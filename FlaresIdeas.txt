Finding separate most discriminative features:

compute featuresets: big, oos

V then for every feature f, and decision_function in (mean, median, std), compute ratios decision_function(f(big))/decision_function(f(big)), sort features by ratios.


We set 99:1 true-
to-false class weights for both algorithms. Both models output scores
are calibrated to MUCH probability of flare class in the validation set.

lstms, rnns, grus classifiers to be fed with entire light curve?


ACTIVE LEARNING:

Для всех рядов, на этапе препроцессинга выкидывать единичные СЛИШКОМ УЖ аномальные выбросы?

out of limited # of known flares, create much wider simulated set when only parts of the series are left, or random parts are missing (simulate non-observation periods)

Для seed samples, создавать много синтетики:
    1) удаляя произвольную точку
    2) добавляя ряд до и после вспышки ?


V Report FI on each iter
lgb,xgb, cb as bootstrap models?

2-phase training?
    1) whole dataset
    2) top-200k by P(flare) only? or maybe clustering?
    
New crowd-labelling platform?
    Social login
Responsible:
    Inviting to projects
    Ratings
Expert quality estimation:
    Concordance scores
    Detailed logging
Multiple featuresets versions (for the same project/target)
Parallel cloud models
Live FIs (Shap)
When some one opens a taks for a first time (or without logging into it for last 2 weeks, or when new instrcutions arrived),
    he is presented with common rules & examples & edge cases of how to classify properly.
    Also labelelr can be TOOLED with specific external links, frames etc (incl keyed).


Стратегия Экспертной Разметки
Вопрос: Как выбрать ~20 примеров для эксперта?
Оптимальная стратегия: Stratified Uncertainty Sampling

def select_for_expert_labeling(
    features: np.ndarray,
    probas: np.ndarray,
    n_samples: int = 20,
) -> list[int]:
    """
    Выбираем примеры для эксперта так, чтобы:
    1. Покрыть разные регионы feature space
    2. Включить примеры с разной уверенностью модели
    3. Максимизировать информативность
    """
    from sklearn.cluster import KMeans

    # 1. Cluster ALL data (not just uncertain)
    n_clusters = n_samples // 2  # ~10 clusters
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(features)

    selected = []

    for cluster_id in range(n_clusters):
        cluster_mask = cluster_labels == cluster_id
        cluster_indices = np.where(cluster_mask)[0]
        cluster_probas = probas[cluster_indices]

        # Из каждого кластера берём:
        # 1. Один НАИБОЛЕЕ uncertain (P ≈ 0.5)
        uncertainty = np.abs(cluster_probas - 0.5)
        most_uncertain = cluster_indices[np.argmin(uncertainty)]
        selected.append(most_uncertain)

        # 2. Один НАИБОЛЕЕ confident positive (P > 0.9)
        high_conf_mask = cluster_probas > 0.9
        if np.any(high_conf_mask):
            high_conf_indices = cluster_indices[high_conf_mask]
            selected.append(high_conf_indices[0])

    return selected[:n_samples]
Почему лучше чем просто UMAP центры:
UMAP/t-SNE теряют информацию → кластеры могут быть артефактами
Мы учитываем И feature space, И model uncertainty
Получаем примеры для проверки И decision boundary, И high-confidence predictions